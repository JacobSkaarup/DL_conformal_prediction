{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtR7sTOi65wJPucpKszzoo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=True)\n","import sys\n","!ls /content/drive/MyDrive/'Colab Notebooks'/conformal-prediction-introduction\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/conformal-prediction-introduction')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SShG8LnHFLdB","executionInfo":{"status":"ok","timestamp":1762779835345,"user_tz":-60,"elapsed":30075,"user":{"displayName":"Jacob Skaarup","userId":"18106995617811723472"}},"outputId":"fd19ecb8-16e2-4253-88fd-cdecf2790c49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive\n","conformal\t    examples   requirements.txt  setup.py\n","conformal.egg-info  README.md  scratch\n"]}]},{"cell_type":"code","source":["!ls '/content/drive/MyDrive/Colab Notebooks/conformal-prediction-introduction/scratch/conformal/holdout_predictions.pth'\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DgF3pqQUHrWa","executionInfo":{"status":"ok","timestamp":1762180148823,"user_tz":-60,"elapsed":109,"user":{"displayName":"Jacob Skaarup","userId":"18106995617811723472"}},"outputId":"61d28967-a3ef-4aa6-8b49-1a88153f160f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cifar10_resnet18.pth  holdout_predictions.pth  val_predictions.pth\n","data\t\t      test_predictions.pth\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYxe85dNE7t8","executionInfo":{"status":"ok","timestamp":1762779893972,"user_tz":-60,"elapsed":51,"user":{"displayName":"Jacob Skaarup","userId":"18106995617811723472"}},"outputId":"3ee5ecdb-5db2-4196-a9bd-96f1a7b30457"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on:  cpu\n","Empirical coverage on validation set: 90.19%\n","Empirical efficiency on validation set: 1.15\n","Empirical singleton coverage on validation set: 95.41%\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4269636198.py:54: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n","Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n","  main()\n"]}],"source":["\n","import torch\n","from torchvision import datasets, transforms, models\n","from conformal.data import IndexedDataset\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from functools import partial\n","\n","\n","# Load stored predictions\n","def main():\n","    print(\"Running on: \", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    folder = \"/content/drive/MyDrive/Colab Notebooks/conformal-prediction-introduction/scratch/conformal\"\n","\n","    holdout_results = torch.load(folder + \"/holdout_predictions.pth\", weights_only=False)\n","    val_results = torch.load(folder + \"/val_predictions.pth\", weights_only=False)\n","\n","    cal_labels = holdout_results[\"labels\"]\n","    cal_outputs = holdout_results[\"outputs\"]\n","    val_outputs = val_results[\"outputs\"]\n","    val_labels = val_results[\"labels\"]\n","    alpha = 0.1  # 90% prediction intervals\n","\n","    # Do conformal calibration\n","    n = len(cal_labels)\n","    cal_scores = 1 - cal_outputs[np.arange(n), cal_labels]\n","    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n","    qhat = np.quantile(cal_scores, q_level, interpolation=\"higher\")\n","    prediction_sets = val_outputs >= (1 - qhat)  # 3: form prediction sets\n","\n","    empirical_coverage = prediction_sets[\n","        np.arange(prediction_sets.shape[0]), val_labels\n","    ].mean()\n","\n","    print(f\"Empirical coverage on validation set: {empirical_coverage * 100:.2f}%\")\n","\n","    empirical_efficiency = prediction_sets.sum(-1).mean()\n","\n","    print(f\"Empirical efficiency on validation set: {empirical_efficiency:.2f}\")\n","\n","    singletons_idx = prediction_sets.sum(-1) == 1\n","    empirical_singleton = prediction_sets[\n","        np.arange(prediction_sets.shape[0]), val_labels\n","    ][singletons_idx].mean()\n","    print(\n","        f\"Empirical singleton coverage on validation set: {empirical_singleton * 100:.2f}%\"\n","    )\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}